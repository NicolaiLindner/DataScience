{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b752b6da-1a00-49bf-ada4-56bc3eef8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbdd24b-64dc-4b60-a557-eec8af1fb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(r'C:\\Programmieren\\Jupyter Lab\\Datasets\\adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab79951b-3822-4c09-ac18-4c092a68513b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>226802</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>89814</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>336951</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>160323</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>103497</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
       "0   25          4  226802          1                7               4   \n",
       "1   38          4   89814         11                9               2   \n",
       "2   28          2  336951          7               12               2   \n",
       "3   44          4  160323         15               10               2   \n",
       "4   18          0  103497         15               10               4   \n",
       "\n",
       "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0           7             3     2       1             0             0   \n",
       "1           5             0     4       1             0             0   \n",
       "2          11             0     4       1             0             0   \n",
       "3           7             0     2       1          7688             0   \n",
       "4           0             3     4       0             0             0   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0              40              39       0  \n",
       "1              50              39       0  \n",
       "2              40              39       1  \n",
       "3              40              39       1  \n",
       "4              30              39       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# List of attributes to encode\n",
    "attributes_to_encode = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "\n",
    "# Apply the encoder to each attribute\n",
    "for attribute in attributes_to_encode:\n",
    "    df[attribute] = le.fit_transform(df[attribute])\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d8ce9c-b33e-468d-bb8d-84b397534091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the uncertain features\n",
    "uncertain_features = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation',\n",
    "                      'relationship', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# List of thresholds\n",
    "thresholds = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# A dictionary to store the modified dataframes\n",
    "modified_dfs = {}\n",
    "\n",
    "# Inserting missing values\n",
    "for thresh in thresholds:\n",
    "    # Create a copy of the original dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # For each uncertain feature, set a proportion of the data to NaN at random\n",
    "    for feature in uncertain_features:\n",
    "        # Find the number of entries to set to NaN\n",
    "        num_nan = int(thresh * len(df_copy[feature]))\n",
    "        \n",
    "        # Generate random indices for NaN insertion\n",
    "        nan_indices = np.random.choice(df_copy.index, num_nan, replace=False)\n",
    "        \n",
    "        # Insert NaNs\n",
    "        df_copy.loc[nan_indices, feature] = np.nan\n",
    "    \n",
    "    # Store the modified dataframe in the dictionary\n",
    "    modified_dfs[f\"df_{int(thresh*100)}\"] = df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b886a310-a968-4fe9-9efb-704587b4a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to store the imputed dataframes\n",
    "imputed_dfs = {}\n",
    "\n",
    "# Imputing missing values\n",
    "for key, mod_df in modified_dfs.items():\n",
    "    # Create copies of the modified dataframe for each imputation method\n",
    "    df_mean = mod_df.copy()\n",
    "    df_median = mod_df.copy()\n",
    "    df_mode = mod_df.copy()\n",
    "    \n",
    "    for feature in uncertain_features:\n",
    "        # Impute missing values with mean\n",
    "        df_mean[feature].fillna(df_mean[feature].mean(), inplace=True)\n",
    "        \n",
    "        # Impute missing values with median\n",
    "        df_median[feature].fillna(df_median[feature].median(), inplace=True)\n",
    "        \n",
    "        # Impute missing values with mode\n",
    "        df_mode[feature].fillna(df_mode[feature].mode()[0], inplace=True)\n",
    "    \n",
    "    # Store the imputed dataframes in the dictionary\n",
    "    imputed_dfs[f\"{key}_mean\"] = df_mean\n",
    "    imputed_dfs[f\"{key}_median\"] = df_median\n",
    "    imputed_dfs[f\"{key}_mode\"] = df_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4693162-28c7-415c-86ab-29d894f64b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['DataFrame', 'Missing', 'Imputation', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC'])\n",
    "\n",
    "# Create an index counter\n",
    "idx = 0\n",
    "\n",
    "# For each DataFrame in the dictionary\n",
    "for key, imp_df in imputed_dfs.items():\n",
    "    # Split the DataFrame into features and target\n",
    "    X = imp_df.drop(target, axis=1)\n",
    "    y = imp_df[target]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the decision tree\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    # Compute the metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test, dt.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    # Parse the key to get the percentage of missing values and the imputation method\n",
    "    missing, imputation = key.split('_')[1], key.split('_')[2]\n",
    "\n",
    "    # Add the results to the results DataFrame\n",
    "    results.loc[idx] = [key, missing, imputation, accuracy, precision, recall, f1, roc_auc]\n",
    "    \n",
    "    # Increment the index counter\n",
    "    idx += 1\n",
    "\n",
    "# To export the results to an Excel file\n",
    "results.to_excel('decision_tree_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cec8b7-8b13-4733-b2be-7a9f24346990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['DataFrame', 'Missing', 'Imputation', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC'])\n",
    "\n",
    "# Create an index counter\n",
    "idx = 0\n",
    "\n",
    "# For each DataFrame in the dictionary\n",
    "for key, imp_df in imputed_dfs.items():\n",
    "    # Split the DataFrame into features and target\n",
    "    X = imp_df.drop(target, axis=1)\n",
    "    y = imp_df[target]\n",
    "    \n",
    "    # Create and train the decision tree\n",
    "    dt = DecisionTreeClassifier()\n",
    "    \n",
    "    # Compute the cross-validated metrics\n",
    "    accuracy = cross_val_score(dt, X, y, cv=5, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(dt, X, y, cv=5, scoring='precision_weighted').mean()\n",
    "    recall = cross_val_score(dt, X, y, cv=5, scoring='recall_weighted').mean()\n",
    "    f1 = cross_val_score(dt, X, y, cv=5, scoring='f1_weighted').mean()\n",
    "    roc_auc = cross_val_score(dt, X, y, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "    # Parse the key to get the percentage of missing values and the imputation method\n",
    "    missing, imputation = key.split('_')[1], key.split('_')[2]\n",
    "\n",
    "    # Add the results to the results DataFrame\n",
    "    results.loc[idx] = [key, missing, imputation, accuracy, precision, recall, f1, roc_auc]\n",
    "    \n",
    "    # Increment the index counter\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebb22df4-c1e3-47a5-ad7c-e6d450117189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Imputation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_5_mean</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.806171</td>\n",
       "      <td>0.808141</td>\n",
       "      <td>0.805577</td>\n",
       "      <td>0.807294</td>\n",
       "      <td>0.738176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_5_median</td>\n",
       "      <td>5</td>\n",
       "      <td>median</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.807907</td>\n",
       "      <td>0.804512</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.738133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_5_mode</td>\n",
       "      <td>5</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.807543</td>\n",
       "      <td>0.810394</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>0.808945</td>\n",
       "      <td>0.742240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_10_mean</td>\n",
       "      <td>10</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.801175</td>\n",
       "      <td>0.803067</td>\n",
       "      <td>0.800704</td>\n",
       "      <td>0.802074</td>\n",
       "      <td>0.732059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df_10_median</td>\n",
       "      <td>10</td>\n",
       "      <td>median</td>\n",
       "      <td>0.800274</td>\n",
       "      <td>0.802511</td>\n",
       "      <td>0.798125</td>\n",
       "      <td>0.800007</td>\n",
       "      <td>0.730354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>df_10_mode</td>\n",
       "      <td>10</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.802998</td>\n",
       "      <td>0.804513</td>\n",
       "      <td>0.801912</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>0.732276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>df_20_mean</td>\n",
       "      <td>20</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.793334</td>\n",
       "      <td>0.797105</td>\n",
       "      <td>0.792351</td>\n",
       "      <td>0.794656</td>\n",
       "      <td>0.727412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>df_20_median</td>\n",
       "      <td>20</td>\n",
       "      <td>median</td>\n",
       "      <td>0.791184</td>\n",
       "      <td>0.793935</td>\n",
       "      <td>0.791163</td>\n",
       "      <td>0.792131</td>\n",
       "      <td>0.719670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>df_20_mode</td>\n",
       "      <td>20</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.797490</td>\n",
       "      <td>0.797972</td>\n",
       "      <td>0.797326</td>\n",
       "      <td>0.798349</td>\n",
       "      <td>0.727076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>df_30_mean</td>\n",
       "      <td>30</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.781172</td>\n",
       "      <td>0.783078</td>\n",
       "      <td>0.781336</td>\n",
       "      <td>0.781324</td>\n",
       "      <td>0.706969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>df_30_median</td>\n",
       "      <td>30</td>\n",
       "      <td>median</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.780644</td>\n",
       "      <td>0.780128</td>\n",
       "      <td>0.780410</td>\n",
       "      <td>0.708830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>df_30_mode</td>\n",
       "      <td>30</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.782851</td>\n",
       "      <td>0.782512</td>\n",
       "      <td>0.782851</td>\n",
       "      <td>0.783434</td>\n",
       "      <td>0.710817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>df_40_mean</td>\n",
       "      <td>40</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.766471</td>\n",
       "      <td>0.769864</td>\n",
       "      <td>0.766963</td>\n",
       "      <td>0.767276</td>\n",
       "      <td>0.686926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>df_40_median</td>\n",
       "      <td>40</td>\n",
       "      <td>median</td>\n",
       "      <td>0.771385</td>\n",
       "      <td>0.769619</td>\n",
       "      <td>0.771058</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.698230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>df_40_mode</td>\n",
       "      <td>40</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.777077</td>\n",
       "      <td>0.775826</td>\n",
       "      <td>0.777855</td>\n",
       "      <td>0.777063</td>\n",
       "      <td>0.705611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>df_50_mean</td>\n",
       "      <td>50</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.761885</td>\n",
       "      <td>0.763721</td>\n",
       "      <td>0.760227</td>\n",
       "      <td>0.761619</td>\n",
       "      <td>0.683398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>df_50_median</td>\n",
       "      <td>50</td>\n",
       "      <td>median</td>\n",
       "      <td>0.764117</td>\n",
       "      <td>0.759581</td>\n",
       "      <td>0.763851</td>\n",
       "      <td>0.762361</td>\n",
       "      <td>0.694207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>df_50_mode</td>\n",
       "      <td>50</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.770546</td>\n",
       "      <td>0.763944</td>\n",
       "      <td>0.769686</td>\n",
       "      <td>0.766572</td>\n",
       "      <td>0.699890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>df_60_mean</td>\n",
       "      <td>60</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.747164</td>\n",
       "      <td>0.748960</td>\n",
       "      <td>0.748475</td>\n",
       "      <td>0.748553</td>\n",
       "      <td>0.671831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>df_60_median</td>\n",
       "      <td>60</td>\n",
       "      <td>median</td>\n",
       "      <td>0.761292</td>\n",
       "      <td>0.750839</td>\n",
       "      <td>0.762766</td>\n",
       "      <td>0.755551</td>\n",
       "      <td>0.688330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>df_60_mode</td>\n",
       "      <td>60</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.762766</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.763790</td>\n",
       "      <td>0.756215</td>\n",
       "      <td>0.694678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>df_70_mean</td>\n",
       "      <td>70</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.744810</td>\n",
       "      <td>0.736575</td>\n",
       "      <td>0.744748</td>\n",
       "      <td>0.740885</td>\n",
       "      <td>0.664390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>df_70_median</td>\n",
       "      <td>70</td>\n",
       "      <td>median</td>\n",
       "      <td>0.762725</td>\n",
       "      <td>0.744796</td>\n",
       "      <td>0.762418</td>\n",
       "      <td>0.750882</td>\n",
       "      <td>0.687329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>df_70_mode</td>\n",
       "      <td>70</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.763728</td>\n",
       "      <td>0.745532</td>\n",
       "      <td>0.763789</td>\n",
       "      <td>0.751804</td>\n",
       "      <td>0.693321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>df_80_mean</td>\n",
       "      <td>80</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.748454</td>\n",
       "      <td>0.722340</td>\n",
       "      <td>0.748045</td>\n",
       "      <td>0.730498</td>\n",
       "      <td>0.672881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>df_80_median</td>\n",
       "      <td>80</td>\n",
       "      <td>median</td>\n",
       "      <td>0.758650</td>\n",
       "      <td>0.727761</td>\n",
       "      <td>0.759408</td>\n",
       "      <td>0.733944</td>\n",
       "      <td>0.692683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>df_80_mode</td>\n",
       "      <td>80</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.760063</td>\n",
       "      <td>0.729868</td>\n",
       "      <td>0.760800</td>\n",
       "      <td>0.735991</td>\n",
       "      <td>0.693927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>df_90_mean</td>\n",
       "      <td>90</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.754658</td>\n",
       "      <td>0.710208</td>\n",
       "      <td>0.755088</td>\n",
       "      <td>0.714612</td>\n",
       "      <td>0.674830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>df_90_median</td>\n",
       "      <td>90</td>\n",
       "      <td>median</td>\n",
       "      <td>0.758097</td>\n",
       "      <td>0.712418</td>\n",
       "      <td>0.758159</td>\n",
       "      <td>0.712383</td>\n",
       "      <td>0.680338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>df_90_mode</td>\n",
       "      <td>90</td>\n",
       "      <td>mode</td>\n",
       "      <td>0.758097</td>\n",
       "      <td>0.711890</td>\n",
       "      <td>0.758057</td>\n",
       "      <td>0.711061</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DataFrame Missing Imputation  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0      df_5_mean       5       mean  0.806171   0.808141  0.805577  0.807294   \n",
       "1    df_5_median       5     median  0.803571   0.807907  0.804512  0.806500   \n",
       "2      df_5_mode       5       mode  0.807543   0.810394  0.808136  0.808945   \n",
       "3     df_10_mean      10       mean  0.801175   0.803067  0.800704  0.802074   \n",
       "4   df_10_median      10     median  0.800274   0.802511  0.798125  0.800007   \n",
       "5     df_10_mode      10       mode  0.802998   0.804513  0.801912  0.802982   \n",
       "6     df_20_mean      20       mean  0.793334   0.797105  0.792351  0.794656   \n",
       "7   df_20_median      20     median  0.791184   0.793935  0.791163  0.792131   \n",
       "8     df_20_mode      20       mode  0.797490   0.797972  0.797326  0.798349   \n",
       "9     df_30_mean      30       mean  0.781172   0.783078  0.781336  0.781324   \n",
       "10  df_30_median      30     median  0.779882   0.780644  0.780128  0.780410   \n",
       "11    df_30_mode      30       mode  0.782851   0.782512  0.782851  0.783434   \n",
       "12    df_40_mean      40       mean  0.766471   0.769864  0.766963  0.767276   \n",
       "13  df_40_median      40     median  0.771385   0.769619  0.771058  0.771032   \n",
       "14    df_40_mode      40       mode  0.777077   0.775826  0.777855  0.777063   \n",
       "15    df_50_mean      50       mean  0.761885   0.763721  0.760227  0.761619   \n",
       "16  df_50_median      50     median  0.764117   0.759581  0.763851  0.762361   \n",
       "17    df_50_mode      50       mode  0.770546   0.763944  0.769686  0.766572   \n",
       "18    df_60_mean      60       mean  0.747164   0.748960  0.748475  0.748553   \n",
       "19  df_60_median      60     median  0.761292   0.750839  0.762766  0.755551   \n",
       "20    df_60_mode      60       mode  0.762766   0.751826  0.763790  0.756215   \n",
       "21    df_70_mean      70       mean  0.744810   0.736575  0.744748  0.740885   \n",
       "22  df_70_median      70     median  0.762725   0.744796  0.762418  0.750882   \n",
       "23    df_70_mode      70       mode  0.763728   0.745532  0.763789  0.751804   \n",
       "24    df_80_mean      80       mean  0.748454   0.722340  0.748045  0.730498   \n",
       "25  df_80_median      80     median  0.758650   0.727761  0.759408  0.733944   \n",
       "26    df_80_mode      80       mode  0.760063   0.729868  0.760800  0.735991   \n",
       "27    df_90_mean      90       mean  0.754658   0.710208  0.755088  0.714612   \n",
       "28  df_90_median      90     median  0.758097   0.712418  0.758159  0.712383   \n",
       "29    df_90_mode      90       mode  0.758097   0.711890  0.758057  0.711061   \n",
       "\n",
       "     ROC AUC  \n",
       "0   0.738176  \n",
       "1   0.738133  \n",
       "2   0.742240  \n",
       "3   0.732059  \n",
       "4   0.730354  \n",
       "5   0.732276  \n",
       "6   0.727412  \n",
       "7   0.719670  \n",
       "8   0.727076  \n",
       "9   0.706969  \n",
       "10  0.708830  \n",
       "11  0.710817  \n",
       "12  0.686926  \n",
       "13  0.698230  \n",
       "14  0.705611  \n",
       "15  0.683398  \n",
       "16  0.694207  \n",
       "17  0.699890  \n",
       "18  0.671831  \n",
       "19  0.688330  \n",
       "20  0.694678  \n",
       "21  0.664390  \n",
       "22  0.687329  \n",
       "23  0.693321  \n",
       "24  0.672881  \n",
       "25  0.692683  \n",
       "26  0.693927  \n",
       "27  0.674830  \n",
       "28  0.680338  \n",
       "29  0.678591  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa936311-d965-4070-9315-2ce9fe7542cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('cross_validation_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01106947-abe4-41a0-b098-2a5c754cc10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141052ea-4c30-435f-9982-2764b5d3d5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
